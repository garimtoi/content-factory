#!/usr/bin/env python
"""
ì¶”ì²œ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

DATABASE_SCHEMA.md Section 8ì— ì •ì˜ëœ 10ê°œ í…Œì´ë¸”ì„ pokervod.dbì— ìƒì„±í•©ë‹ˆë‹¤.

Usage:
    python scripts/migrate_recommendation_schema.py --dry-run  # ì‹œë®¬ë ˆì´ì…˜
    python scripts/migrate_recommendation_schema.py            # ì‹¤í–‰
    python scripts/migrate_recommendation_schema.py --rollback # ë¡¤ë°±
"""

import argparse
import sqlite3
import sys
from datetime import datetime
from pathlib import Path

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding="utf-8")

# ê²½ë¡œ ì„¤ì •
POKERVOD_DB = Path("D:/AI/claude01/qwen_hand_analysis/data/pokervod.db")

# ì‹ ê·œ í…Œì´ë¸” DDL ì •ì˜
TABLES = {
    "recommendation_cache": """
        CREATE TABLE IF NOT EXISTS recommendation_cache (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id VARCHAR(50) NOT NULL,
            rec_type VARCHAR(50) NOT NULL,
            context_item_id VARCHAR(200),
            items JSON NOT NULL,
            algorithm VARCHAR(50) NOT NULL DEFAULT 'gorse',
            model_version VARCHAR(50),
            expires_at TIMESTAMP NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(user_id, rec_type, context_item_id)
        )
    """,
    "trending_scores": """
        CREATE TABLE IF NOT EXISTS trending_scores (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            file_id VARCHAR(200) NOT NULL,
            catalog_id VARCHAR(50),
            time_bucket TIMESTAMP NOT NULL,
            view_count INTEGER DEFAULT 0,
            unique_viewers INTEGER DEFAULT 0,
            avg_completion_rate FLOAT DEFAULT 0,
            avg_watch_duration FLOAT DEFAULT 0,
            trending_score FLOAT DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(file_id, time_bucket),
            FOREIGN KEY (file_id) REFERENCES files(id),
            FOREIGN KEY (catalog_id) REFERENCES catalogs(id)
        )
    """,
    "home_rows": """
        CREATE TABLE IF NOT EXISTS home_rows (
            id VARCHAR(50) PRIMARY KEY,
            row_type VARCHAR(50) NOT NULL,
            title VARCHAR(200) NOT NULL,
            title_template VARCHAR(200),
            algorithm VARCHAR(50),
            query_params JSON,
            default_position INTEGER DEFAULT 0,
            is_active BOOLEAN DEFAULT TRUE,
            requires_history BOOLEAN DEFAULT FALSE,
            min_items INTEGER DEFAULT 5,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """,
    "user_home_rows": """
        CREATE TABLE IF NOT EXISTS user_home_rows (
            user_id VARCHAR(50) NOT NULL,
            row_id VARCHAR(50) NOT NULL,
            position INTEGER,
            is_visible BOOLEAN DEFAULT TRUE,
            is_personalized BOOLEAN DEFAULT TRUE,
            context_item_id VARCHAR(200),
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (user_id, row_id),
            FOREIGN KEY (user_id) REFERENCES users(id),
            FOREIGN KEY (row_id) REFERENCES home_rows(id)
        )
    """,
    "artwork_variants": """
        CREATE TABLE IF NOT EXISTS artwork_variants (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            file_id VARCHAR(200) NOT NULL,
            variant_type VARCHAR(50) NOT NULL DEFAULT 'default',
            image_url TEXT NOT NULL,
            thumbnail_time_sec FLOAT,
            focus_player VARCHAR(100),
            dominant_emotion VARCHAR(50),
            tags JSON,
            generated_by VARCHAR(50) DEFAULT 'ffmpeg',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (file_id) REFERENCES files(id)
        )
    """,
    "artwork_selections": """
        CREATE TABLE IF NOT EXISTS artwork_selections (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id VARCHAR(50) NOT NULL,
            file_id VARCHAR(200) NOT NULL,
            artwork_id INTEGER NOT NULL,
            impressions INTEGER DEFAULT 0,
            clicks INTEGER DEFAULT 0,
            context JSON,
            selected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(user_id, file_id),
            FOREIGN KEY (user_id) REFERENCES users(id),
            FOREIGN KEY (file_id) REFERENCES files(id),
            FOREIGN KEY (artwork_id) REFERENCES artwork_variants(id)
        )
    """,
    "experiments": """
        CREATE TABLE IF NOT EXISTS experiments (
            id VARCHAR(50) PRIMARY KEY,
            name VARCHAR(200) NOT NULL,
            description TEXT,
            variants JSON NOT NULL,
            target_metric VARCHAR(100),
            start_date TIMESTAMP,
            end_date TIMESTAMP,
            status VARCHAR(20) DEFAULT 'draft',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """,
    "experiment_assignments": """
        CREATE TABLE IF NOT EXISTS experiment_assignments (
            user_id VARCHAR(50) NOT NULL,
            experiment_id VARCHAR(50) NOT NULL,
            variant_id VARCHAR(50) NOT NULL,
            assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (user_id, experiment_id),
            FOREIGN KEY (user_id) REFERENCES users(id),
            FOREIGN KEY (experiment_id) REFERENCES experiments(id)
        )
    """,
    "user_embeddings": """
        CREATE TABLE IF NOT EXISTS user_embeddings (
            user_id VARCHAR(50) PRIMARY KEY,
            embedding BLOB NOT NULL,
            algorithm VARCHAR(50) NOT NULL,
            model_version VARCHAR(50),
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users(id)
        )
    """,
    "item_embeddings": """
        CREATE TABLE IF NOT EXISTS item_embeddings (
            item_id VARCHAR(200) NOT NULL,
            item_type VARCHAR(50) NOT NULL,
            embedding BLOB NOT NULL,
            algorithm VARCHAR(50) NOT NULL,
            model_version VARCHAR(50),
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (item_id, item_type)
        )
    """,
}

# ì¸ë±ìŠ¤ ì •ì˜
INDEXES = {
    "recommendation_cache": [
        "CREATE INDEX IF NOT EXISTS idx_rec_cache_user ON recommendation_cache(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_rec_cache_expires ON recommendation_cache(expires_at)",
    ],
    "trending_scores": [
        "CREATE INDEX IF NOT EXISTS idx_trending_bucket ON trending_scores(time_bucket)",
        "CREATE INDEX IF NOT EXISTS idx_trending_score ON trending_scores(trending_score DESC)",
        "CREATE INDEX IF NOT EXISTS idx_trending_catalog ON trending_scores(catalog_id, time_bucket)",
    ],
    "artwork_variants": [
        "CREATE INDEX IF NOT EXISTS idx_artwork_file ON artwork_variants(file_id)",
        "CREATE INDEX IF NOT EXISTS idx_artwork_player ON artwork_variants(focus_player)",
    ],
}

# ê¸°ë³¸ home_rows ë°ì´í„°
DEFAULT_HOME_ROWS = [
    ("continue_watching", "continue", "ê³„ì† ì‹œì²­í•˜ê¸°", None, "watch_progress", None, 1, True, True, 1),
    ("trending_all", "trending", "ì§€ê¸ˆ ì¸ê¸° ìˆëŠ” ì˜ìƒ", None, "trending_24h", None, 2, True, False, 5),
    ("trending_wsop", "trending", "WSOP ì¸ê¸° ì˜ìƒ", None, "trending_24h", '{"catalog_id": "WSOP"}', 3, True, False, 5),
    ("trending_hcl", "trending", "HCL ì¸ê¸° ì˜ìƒ", None, "trending_24h", '{"catalog_id": "HCL"}', 4, True, False, 5),
    ("new_releases", "category", "ìƒˆë¡œ ì¶”ê°€ëœ ì˜ìƒ", None, "recent", None, 5, True, False, 5),
    ("personalized_for_you", "personalized", "ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ", None, "gorse_hybrid", None, 6, True, True, 5),
    ("because_watched", "personalized", "{title} ì‹œì²­ í›„ ì¶”ì²œ", "{title} ì‹œì²­ í›„ ì¶”ì²œ", "similar_items", None, 7, True, True, 3),
    ("top_hands", "curated", "ë² ìŠ¤íŠ¸ í•¸ë“œ ëª¨ìŒ", None, "highlight_score", '{"min_score": 3}', 8, True, False, 5),
    ("favorite_players", "personalized", "ì¦ê²¨ì°¾ëŠ” í”Œë ˆì´ì–´", None, "player_based", None, 9, True, True, 3),
]


def get_existing_tables(conn: sqlite3.Connection) -> set:
    """ê¸°ì¡´ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    cursor = conn.execute(
        "SELECT name FROM sqlite_master WHERE type='table'"
    )
    return {row[0] for row in cursor.fetchall()}


def migrate(conn: sqlite3.Connection, dry_run: bool = False) -> dict:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    results = {
        "tables_created": [],
        "tables_skipped": [],
        "indexes_created": [],
        "data_inserted": [],
    }

    existing_tables = get_existing_tables(conn)

    # 1. í…Œì´ë¸” ìƒì„±
    for table_name, ddl in TABLES.items():
        if table_name in existing_tables:
            results["tables_skipped"].append(table_name)
            print(f"â­ï¸  {table_name}: ì´ë¯¸ ì¡´ì¬ (ìŠ¤í‚µ)")
        else:
            if dry_run:
                print(f"ğŸ” {table_name}: ìƒì„± ì˜ˆì •")
            else:
                conn.execute(ddl)
                print(f"âœ… {table_name}: ìƒì„± ì™„ë£Œ")
            results["tables_created"].append(table_name)

    # 2. ì¸ë±ìŠ¤ ìƒì„±
    for table_name, index_ddls in INDEXES.items():
        for index_ddl in index_ddls:
            index_name = index_ddl.split("IF NOT EXISTS ")[1].split(" ON")[0]
            if dry_run:
                print(f"ğŸ” {index_name}: ìƒì„± ì˜ˆì •")
            else:
                conn.execute(index_ddl)
                print(f"âœ… {index_name}: ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            results["indexes_created"].append(index_name)

    # 3. ê¸°ë³¸ ë°ì´í„° ì‚½ì… (home_rows)
    if "home_rows" in results["tables_created"]:
        if dry_run:
            print(f"ğŸ” home_rows: {len(DEFAULT_HOME_ROWS)}ê°œ ê¸°ë³¸ ë°ì´í„° ì‚½ì… ì˜ˆì •")
        else:
            conn.executemany(
                """
                INSERT INTO home_rows
                (id, row_type, title, title_template, algorithm, query_params,
                 default_position, is_active, requires_history, min_items)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                DEFAULT_HOME_ROWS
            )
            print(f"âœ… home_rows: {len(DEFAULT_HOME_ROWS)}ê°œ ê¸°ë³¸ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
        results["data_inserted"].append(f"home_rows: {len(DEFAULT_HOME_ROWS)} rows")

    if not dry_run:
        conn.commit()

    return results


def rollback(conn: sqlite3.Connection, dry_run: bool = False) -> dict:
    """ë¡¤ë°± ì‹¤í–‰ (í…Œì´ë¸” ì‚­ì œ)"""
    results = {
        "tables_dropped": [],
        "tables_not_found": [],
    }

    existing_tables = get_existing_tables(conn)

    # ì—­ìˆœìœ¼ë¡œ ì‚­ì œ (ì˜ì¡´ì„± ê³ ë ¤)
    for table_name in reversed(list(TABLES.keys())):
        if table_name in existing_tables:
            if dry_run:
                print(f"ğŸ” {table_name}: ì‚­ì œ ì˜ˆì •")
            else:
                conn.execute(f"DROP TABLE IF EXISTS {table_name}")
                print(f"ğŸ—‘ï¸  {table_name}: ì‚­ì œ ì™„ë£Œ")
            results["tables_dropped"].append(table_name)
        else:
            results["tables_not_found"].append(table_name)
            print(f"â­ï¸  {table_name}: ì¡´ì¬í•˜ì§€ ì•ŠìŒ (ìŠ¤í‚µ)")

    if not dry_run:
        conn.commit()

    return results


def verify(conn: sqlite3.Connection) -> dict:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦"""
    results = {
        "existing": [],
        "missing": [],
        "row_counts": {},
    }

    existing_tables = get_existing_tables(conn)

    for table_name in TABLES.keys():
        if table_name in existing_tables:
            results["existing"].append(table_name)
            cursor = conn.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = cursor.fetchone()[0]
            results["row_counts"][table_name] = count
        else:
            results["missing"].append(table_name)

    return results


def main():
    parser = argparse.ArgumentParser(
        description="ì¶”ì²œ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ì‹¤ì œ ë³€ê²½ ì—†ìŒ)"
    )
    parser.add_argument(
        "--rollback",
        action="store_true",
        help="ë¡¤ë°± ëª¨ë“œ (í…Œì´ë¸” ì‚­ì œ)"
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="ê²€ì¦ ëª¨ë“œ (ìƒíƒœ í™•ì¸)"
    )
    parser.add_argument(
        "--db-path",
        type=str,
        default=str(POKERVOD_DB),
        help=f"DB ê²½ë¡œ (ê¸°ë³¸ê°’: {POKERVOD_DB})"
    )

    args = parser.parse_args()

    # DB ì—°ê²°
    db_path = Path(args.db_path)
    if not db_path.exists():
        print(f"âŒ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        sys.exit(1)

    print(f"ğŸ“ DB: {db_path}")
    print(f"ğŸ“… ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 50)

    conn = sqlite3.connect(str(db_path))

    try:
        if args.verify:
            print("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ ê²€ì¦\n")
            results = verify(conn)

            print(f"\nâœ… ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”: {len(results['existing'])}/{len(TABLES)}")
            for table in results["existing"]:
                count = results["row_counts"].get(table, 0)
                print(f"   - {table}: {count} rows")

            if results["missing"]:
                print(f"\nâŒ ëˆ„ë½ëœ í…Œì´ë¸”: {len(results['missing'])}")
                for table in results["missing"]:
                    print(f"   - {table}")

        elif args.rollback:
            print(f"{'ğŸ” ë¡¤ë°± ì‹œë®¬ë ˆì´ì…˜' if args.dry_run else 'ğŸ—‘ï¸  ë¡¤ë°± ì‹¤í–‰'}\n")
            results = rollback(conn, dry_run=args.dry_run)

            print(f"\nğŸ“Š ê²°ê³¼:")
            print(f"   ì‚­ì œëœ í…Œì´ë¸”: {len(results['tables_dropped'])}")
            print(f"   ì—†ëŠ” í…Œì´ë¸”: {len(results['tables_not_found'])}")

        else:
            print(f"{'ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë®¬ë ˆì´ì…˜' if args.dry_run else 'ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰'}\n")
            results = migrate(conn, dry_run=args.dry_run)

            print(f"\nğŸ“Š ê²°ê³¼:")
            print(f"   ìƒì„±ëœ í…Œì´ë¸”: {len(results['tables_created'])}")
            print(f"   ìŠ¤í‚µëœ í…Œì´ë¸”: {len(results['tables_skipped'])}")
            print(f"   ìƒì„±ëœ ì¸ë±ìŠ¤: {len(results['indexes_created'])}")

            if results["data_inserted"]:
                print(f"   ì‚½ì…ëœ ë°ì´í„°:")
                for data in results["data_inserted"]:
                    print(f"      - {data}")

    finally:
        conn.close()

    print("\nâœ¨ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
